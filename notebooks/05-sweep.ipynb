{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d423bb-e164-4cd2-9f3e-ca3e265b3925",
   "metadata": {},
   "source": [
    "# PointNet for particle flow\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "This notebook showcases the sweep functionality offered by W&B.\n",
    "\n",
    "Sweeps are useful to to automate hyperparameter search and visualize rich, interactive experiment tracking. They basically work as a scheduler of several experiments in fixed conditions, but varying for a few sweep parameters.\n",
    "\n",
    "Hence, we can use sweeps defining a some hyperparameters to be tuned and a grid/distribution for possible values to attempt, and the wandb UI takes care of spawning several training jobs for different values of the hyperparameters.\n",
    "\n",
    "How the values of each experiment are set can be chosen from three different sampling schema:\n",
    " - grid search\n",
    " - random search\n",
    " - Bayesian optimization\n",
    "\n",
    "**Main changes:** \n",
    "\n",
    "- repeat full pipeline for different learning rates exploiting wandb sweeps\n",
    "\n",
    "</div>\n",
    "\n",
    "## Problem\n",
    "\n",
    "This dataset contains a Monte Carlo simulation of $\\rho^{\\pm} \\rightarrow \\pi^{\\pm} + \\pi^0$ decays and the corresponding detector response. Specifically, the data report the measured response of **i) tracker** and **ii) calorimeter**, along with the true pyshical quantitites that generated those measurements.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "This means that we expect one track per event, with mainly two energy blobs (clusters of cells) in the calorimeter.\n",
    "</div>\n",
    "\n",
    "The final **goal** is to associate the cell signals observed in the calorimeter to the track that caused those energy deposits.\n",
    "\n",
    "## Method\n",
    "\n",
    "The idea is to leverage a **point cloud** data representation to combine tracker and calorimeter information so to associate cell hits to the corresponding track. We will use a [**PointNet**](https://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf) model that is capable of handling this type of data, framed as a **semantic segmentation** approach. More precisely, this means that:\n",
    "- we represent each hit in the detector as a point in the point cloud: x, y, z coordinates + additional features (\"3+\"-dimensional point)\n",
    "- the **learning task** will be binary classification at hit level: for each cell the model learns whether its energy comes mostly from the track (class 1) or not (class 0)\n",
    "\n",
    "## Data structure\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "This dataset is organized as follows:\n",
    " - for each event, we create a **sample** (i.e. point cloud)\n",
    " - each sample contains all hits in a cone around a track of the event, called **focal track**\n",
    "     - the cone includes all hits within some $\\Delta R$ distance of the track\n",
    "     - if an event has multiple tracks, then we have more samples per event\n",
    "     - since different samples have possibly different number of hits, **we pad all point clouds to ensure they have same size** (needed since the model requires inputs of same size)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576b6bf-eb45-4742-8f24-1023d6e0cc15",
   "metadata": {},
   "source": [
    "## Settings & config\n",
    "\n",
    "This section collects all configuration variables and training/model hyperparameters. \n",
    "\n",
    "The idea is to put it at the top so that it is easy to find and edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c725801-a326-486d-97ca-5a165b2bbb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 15:02:01.204243: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 15:02:03.433660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# path settings\n",
    "REPO_BASEPATH = Path().cwd().parent\n",
    "DATA_PATH = REPO_BASEPATH / \"pnet_data/raw/rho_small.npz\"\n",
    "CODE_PATH = REPO_BASEPATH / \"src\"\n",
    "sys.path.append(str(CODE_PATH))\n",
    "MODEL_CHECKPOINTS_PATH = REPO_BASEPATH / \"results\" / \"models\" / \"pointnet_baseline.weights.h5\"\n",
    "\n",
    "import wandb\n",
    "from data_viz import *\n",
    "from model_utils import *\n",
    "\n",
    "LABELS = [\"unfocus hit\", \"focus hit\"]\n",
    "\n",
    "# set random seed for reproducibility\n",
    "SEED = 18\n",
    "set_global_seeds(SEED)\n",
    "\n",
    "# data settings\n",
    "N_TRAIN, N_VAL, N_TEST = 210, 65, 50 # roughly 0.65, 0.2, 0.15\n",
    "\n",
    "# model settings\n",
    "N_FEATURES = 3\n",
    "INIT_SIZE = 8\n",
    "END_SIZE = 16\n",
    "\n",
    "# training settings\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "INIT_LR = 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54eb0a-6709-42c1-8f92-7b1b84e7d9de",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Model training\n",
    "\n",
    "We proceed with model training:\n",
    "\n",
    "1. split the data\n",
    "1. build our PointNet model using Tensorflow/Keras\n",
    "1. create a dataloader to feed batches into our model\n",
    "1. train\n",
    "1. check results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776985d-5603-4049-b25b-92462ac5c187",
   "metadata": {},
   "source": [
    "### PointNet model \n",
    "\n",
    "We use a PointNet model for semantic segmentation. Here is an illustration of its structure:\n",
    "\n",
    "![PointNet architecture](../pnet_data/images/pointnet-architecture.jpg)\n",
    "\n",
    "We have two heads:\n",
    " - classification head (used for point cloud classification)\n",
    " - segmentation head (used for semantic segmentation)\n",
    "\n",
    "We are going to use the **segmentation head** for our problem. The architecture settings we can experiment with are:\n",
    " - `n_features` (the number of input features): original version has only size 3 as it only takes x,y,z coordinates\n",
    " - `init_size` (number of filters of first convolutional layer): original version has 64\n",
    " - `end_size` (number of filters in segmentation head): original version has 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7538ad2a-9c2e-4a71-8893-4a99ec35a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "def read_data(split, bin_cutoff=0.5, n_classes=2):\n",
    "    split_data_path = DATA_PATH.parent.parent\n",
    "    filepath=str(split_data_path / f\"{split}_data\" / DATA_PATH.name)\n",
    "    data = np.load(filepath)['feats']\n",
    "    target_class = [(energy_fraction > bin_cutoff).astype(np.float32) \n",
    "                    for energy_fraction in data['truth_cell_focal_fraction_energy']]\n",
    "    # target_class = (events[\"truth_cell_focal_fraction_energy\"] > 0.5).reshape(-1)\n",
    "    target_class = keras.utils.to_categorical(target_class, num_classes=n_classes)\n",
    "    return data, target_class\n",
    "    \n",
    "\n",
    "def train_wrapper():\n",
    "    run = wandb.init(project=\"mlops-ai_infn\", entity=\"lclissa\", name=\"first-sweep\",\n",
    "                job_type=\"sweep\", notes=\"Playing with sweeps ...\")\n",
    "    cfg = run.config\n",
    "    input_features = [\"normalized_x\", \"normalized_y\", \"normalized_z\"]\n",
    "\n",
    "    train_data, train_label_cloud = read_data(\"train\")\n",
    "    \n",
    "    train_point_clouds = train_data[input_features]\n",
    "    total_training_examples = len(train_point_clouds)\n",
    "    \n",
    "    val_data, val_label_cloud = read_data(\"val\")\n",
    "    val_point_clouds = val_data[input_features]\n",
    "    \n",
    "    print(\"Num train point clouds:\", len(train_point_clouds))\n",
    "    print(\"Num train point cloud labels:\", len(train_label_cloud))\n",
    "    print(\"Num val point clouds:\", len(val_point_clouds))\n",
    "    print(\"Num val point cloud labels:\", len(val_label_cloud))\n",
    "    \n",
    "    n_points = train_point_clouds[0].shape[0]\n",
    "    n_features = len(train_point_clouds[0].dtype.names)\n",
    "    n_classes = len(LABELS)\n",
    "\n",
    "    _ = run.use_artifact(\"train_data:latest\")\n",
    "    _ = run.use_artifact(\"val_data:latest\")\n",
    "    \n",
    "    train_dataset = generate_dataset(train_point_clouds, train_label_cloud, \n",
    "                                 bs=cfg.batch_size, n_points=n_points, n_features=n_features, labels=LABELS)\n",
    "    val_dataset = generate_dataset(val_point_clouds, val_label_cloud, is_training=False, \n",
    "                                   bs=cfg.batch_size, n_points=n_points, n_features=n_features, labels=LABELS)\n",
    "\n",
    "    \n",
    "    steps_per_epoch = total_training_examples // cfg.batch_size\n",
    "    total_training_steps = steps_per_epoch * EPOCHS\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=cfg.init_lr,\n",
    "        decay_steps=steps_per_epoch * 5,\n",
    "        decay_rate=0.5,\n",
    "        staircase=True,\n",
    "    )\n",
    "\n",
    "    segmentation_model = get_shape_segmentation_model(n_points, n_classes, n_features,\n",
    "                                                      INIT_SIZE, END_SIZE)\n",
    "    segmentation_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "        jit_compile=False\n",
    "    )\n",
    "\n",
    "    MODEL_CHECKPOINTS_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
    "    history = segmentation_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[\n",
    "            WandbMetricsLogger(log_freq=5),\n",
    "            WandbModelCheckpoint(\n",
    "                       MODEL_CHECKPOINTS_PATH, #.parent / \"model-{epoch:02d}-{val_loss:.2f}.weights.h5\",\n",
    "                       monitor=\"val_loss\",\n",
    "                       save_best_only=True,\n",
    "                       save_weights_only=True,\n",
    "                   )\n",
    "        ],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a87203-a5b0-4c29-bbce-38a872237672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 59n7uolz\n",
      "Sweep URL: https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vnv2uawp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 0.01777628046019689\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/private/mlops-handson/notebooks/wandb/run-20241126_150819-vnv2uawp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/vnv2uawp' target=\"_blank\">first-sweep</a></strong> to <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/vnv2uawp' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/vnv2uawp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train point clouds: 210\n",
      "Num train point cloud labels: 210\n",
      "Num val point clouds: 65\n",
      "Num val point cloud labels: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 15:08:29.809430: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732633710.498502   20164 service.cc:145] XLA service 0x7f022b6a5490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732633710.498554   20164 service.cc:153]   StreamExecutor device (0): NVIDIA A100 80GB PCIe MIG 1g.10gb, Compute Capability 8.0\n",
      "I0000 00:00:1732633710.630396   20164 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 266ms/step - accuracy: 0.5061 - loss: 121.2791 - val_accuracy: 0.8794 - val_loss: 31.4203\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.8680 - loss: 62.6697 - val_accuracy: 0.8734 - val_loss: 26.3510\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8826 - loss: 23.2022 - val_accuracy: 0.8734 - val_loss: 21.8321\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8853 - loss: 21.6856 - val_accuracy: 0.8734 - val_loss: 20.8322\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8758 - loss: 21.3526 - val_accuracy: 0.8734 - val_loss: 22.5084\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8789 - loss: 19.4142 - val_accuracy: 0.8734 - val_loss: 24.5993\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8796 - loss: 18.6276 - val_accuracy: 0.8734 - val_loss: 25.4745\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8896 - loss: 17.9955 - val_accuracy: 0.8734 - val_loss: 24.4901\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8777 - loss: 17.9499 - val_accuracy: 0.8734 - val_loss: 23.6704\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8864 - loss: 17.8550 - val_accuracy: 0.8734 - val_loss: 23.3925\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8819 - loss: 17.8015 - val_accuracy: 0.8734 - val_loss: 23.1404\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8765 - loss: 17.7235 - val_accuracy: 0.8734 - val_loss: 22.9886\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8878 - loss: 17.6986 - val_accuracy: 0.8734 - val_loss: 22.9693\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8791 - loss: 17.6940 - val_accuracy: 0.8734 - val_loss: 22.9073\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8756 - loss: 17.6285 - val_accuracy: 0.8734 - val_loss: 22.9918\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8829 - loss: 17.6666 - val_accuracy: 0.8734 - val_loss: 22.8566\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8841 - loss: 17.6503 - val_accuracy: 0.8734 - val_loss: 22.7755\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8830 - loss: 17.6580 - val_accuracy: 0.8734 - val_loss: 22.6017\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8828 - loss: 17.6404 - val_accuracy: 0.8734 - val_loss: 22.3608\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8849 - loss: 17.6241 - val_accuracy: 0.8734 - val_loss: 22.2229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▅▇█████████████████████████▇███████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>█████████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>▂██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>████▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▅▂▁▂▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.88031</td></tr><tr><td>batch/batch_step</td><td>195</td></tr><tr><td>batch/learning_rate</td><td>0.00111</td></tr><tr><td>batch/loss</td><td>17.88671</td></tr><tr><td>epoch/accuracy</td><td>0.8808</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.00111</td></tr><tr><td>epoch/loss</td><td>16.84585</td></tr><tr><td>epoch/val_accuracy</td><td>0.8734</td></tr><tr><td>epoch/val_loss</td><td>22.22291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">first-sweep</strong> at: <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/vnv2uawp' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/vnv2uawp</a><br/> View project at: <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a><br/>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241126_150819-vnv2uawp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5y57pz2t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 0.025237308361077924\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/private/mlops-handson/notebooks/wandb/run-20241126_150900-5y57pz2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/5y57pz2t' target=\"_blank\">first-sweep</a></strong> to <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/5y57pz2t' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/5y57pz2t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train point clouds: 210\n",
      "Num train point cloud labels: 210\n",
      "Num val point clouds: 65\n",
      "Num val point cloud labels: 65\n",
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.8483 - loss: 347.7976 - val_accuracy: 0.8710 - val_loss: 28.6059\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8766 - loss: 90.9613 - val_accuracy: 0.8734 - val_loss: 26.9146\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.8858 - loss: 35.2022 - val_accuracy: 0.8734 - val_loss: 26.5475\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8778 - loss: 29.8500 - val_accuracy: 0.8734 - val_loss: 32.0064\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8863 - loss: 24.8005 - val_accuracy: 0.8734 - val_loss: 33.6126\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8675 - loss: 23.0035 - val_accuracy: 0.8740 - val_loss: 32.6369\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8829 - loss: 21.7568 - val_accuracy: 0.8734 - val_loss: 36.6848\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8758 - loss: 21.8375 - val_accuracy: 0.8734 - val_loss: 38.1628\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8747 - loss: 20.1752 - val_accuracy: 0.8734 - val_loss: 39.4485\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8725 - loss: 19.9585 - val_accuracy: 0.8734 - val_loss: 41.3763\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8849 - loss: 19.7563 - val_accuracy: 0.8734 - val_loss: 41.8158\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8844 - loss: 19.4074 - val_accuracy: 0.8734 - val_loss: 41.0943\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8767 - loss: 19.4185 - val_accuracy: 0.8734 - val_loss: 40.2938\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8786 - loss: 19.2899 - val_accuracy: 0.8734 - val_loss: 40.5772\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8770 - loss: 19.2628 - val_accuracy: 0.8734 - val_loss: 39.6251\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8752 - loss: 19.1456 - val_accuracy: 0.8734 - val_loss: 38.4471\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8766 - loss: 19.1105 - val_accuracy: 0.8734 - val_loss: 37.0780\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8789 - loss: 19.1542 - val_accuracy: 0.8734 - val_loss: 35.7333\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8703 - loss: 18.9086 - val_accuracy: 0.8734 - val_loss: 34.4428\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8754 - loss: 19.0391 - val_accuracy: 0.8734 - val_loss: 33.2136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▅▆▆█▇▆▆█▆▄▆▇▆▆▆▆▆▆▆▇▆█▆▇▆▇▆▆▆▅▆▇▆▇▆▆▆▅▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>█████████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>▁█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁█▇▇█▇█▇█▆█▇▇▇▇▇▇▇▆█</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>████▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch/val_loss</td><td>▂▁▁▄▄▄▆▆▇███▇▇▇▆▆▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.88027</td></tr><tr><td>batch/batch_step</td><td>195</td></tr><tr><td>batch/learning_rate</td><td>0.00158</td></tr><tr><td>batch/loss</td><td>19.273</td></tr><tr><td>epoch/accuracy</td><td>0.87942</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.00158</td></tr><tr><td>epoch/loss</td><td>18.16093</td></tr><tr><td>epoch/val_accuracy</td><td>0.87344</td></tr><tr><td>epoch/val_loss</td><td>33.21358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">first-sweep</strong> at: <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/5y57pz2t' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/5y57pz2t</a><br/> View project at: <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241126_150900-5y57pz2t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: olo8nnp5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 0.0934809629875714\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/private/mlops-handson/notebooks/wandb/run-20241126_150932-olo8nnp5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/olo8nnp5' target=\"_blank\">first-sweep</a></strong> to <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/olo8nnp5' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/olo8nnp5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train point clouds: 210\n",
      "Num train point cloud labels: 210\n",
      "Num val point clouds: 65\n",
      "Num val point cloud labels: 65\n",
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 212ms/step - accuracy: 0.6584 - loss: 26890.3574 - val_accuracy: 0.8734 - val_loss: 6608828850241536.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8705 - loss: 3035.0254 - val_accuracy: 0.8734 - val_loss: 23685463981271547904.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8904 - loss: 1607.7148 - val_accuracy: 0.8734 - val_loss: 20343584150553362432.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8755 - loss: 489.6666 - val_accuracy: 0.8734 - val_loss: 1887335623455408128.0000\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8787 - loss: 193.2845 - val_accuracy: 0.8734 - val_loss: 112489247931367424.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8712 - loss: 149.8467 - val_accuracy: 0.8734 - val_loss: 8883955705053184.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8739 - loss: 123.2915 - val_accuracy: 0.8734 - val_loss: 1133076528758784.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8833 - loss: 109.1619 - val_accuracy: 0.8734 - val_loss: 194357370028032.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.8809 - loss: 94.9604 - val_accuracy: 0.8734 - val_loss: 42608705404928.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8782 - loss: 91.6861 - val_accuracy: 0.8734 - val_loss: 11065346752512.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.8777 - loss: 88.1173 - val_accuracy: 0.8734 - val_loss: 3384801230848.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8805 - loss: 86.1220 - val_accuracy: 0.8734 - val_loss: 1161447735296.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.8787 - loss: 83.3689 - val_accuracy: 0.8734 - val_loss: 446648287232.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.8788 - loss: 78.9766 - val_accuracy: 0.8734 - val_loss: 186784333824.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8798 - loss: 78.0725 - val_accuracy: 0.8734 - val_loss: 84005175296.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8768 - loss: 76.4721 - val_accuracy: 0.8734 - val_loss: 37579444224.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8827 - loss: 73.5073 - val_accuracy: 0.8734 - val_loss: 17247758336.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.8840 - loss: 75.0788 - val_accuracy: 0.8734 - val_loss: 8120300544.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.8746 - loss: 74.1919 - val_accuracy: 0.8734 - val_loss: 3861412352.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8798 - loss: 71.8143 - val_accuracy: 0.8734 - val_loss: 1925366528.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▆▇███▇███▇█▇███████▇█████████▇█████▇███</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>█████████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>▁█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>████▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>▁█▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.87598</td></tr><tr><td>batch/batch_step</td><td>195</td></tr><tr><td>batch/learning_rate</td><td>0.00584</td></tr><tr><td>batch/loss</td><td>74.32471</td></tr><tr><td>epoch/accuracy</td><td>0.87831</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.00584</td></tr><tr><td>epoch/loss</td><td>70.01779</td></tr><tr><td>epoch/val_accuracy</td><td>0.87344</td></tr><tr><td>epoch/val_loss</td><td>1925366528.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">first-sweep</strong> at: <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/olo8nnp5' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/olo8nnp5</a><br/> View project at: <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a><br/>Synced 5 W&B file(s), 0 media file(s), 30 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241126_150932-olo8nnp5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yfydrg8r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 0.010466751138827763\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/private/mlops-handson/notebooks/wandb/run-20241126_151034-yfydrg8r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/yfydrg8r' target=\"_blank\">first-sweep</a></strong> to <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/yfydrg8r' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/yfydrg8r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train point clouds: 210\n",
      "Num train point cloud labels: 210\n",
      "Num val point clouds: 65\n",
      "Num val point cloud labels: 65\n",
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.5987 - loss: 42.1127 - val_accuracy: 0.8751 - val_loss: 30.7271\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.8575 - loss: 30.1240 - val_accuracy: 0.8734 - val_loss: 27.4938\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.8701 - loss: 19.8802 - val_accuracy: 0.8734 - val_loss: 24.1101\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8727 - loss: 18.2878 - val_accuracy: 0.8734 - val_loss: 21.6381\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8791 - loss: 18.3399 - val_accuracy: 0.8734 - val_loss: 20.5214\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.8796 - loss: 17.9241 - val_accuracy: 0.8734 - val_loss: 19.9021\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.8755 - loss: 17.7300 - val_accuracy: 0.8734 - val_loss: 19.2988\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.8797 - loss: 17.5962 - val_accuracy: 0.8734 - val_loss: 18.7513\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.8702 - loss: 17.5056 - val_accuracy: 0.8734 - val_loss: 18.3992\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.8813 - loss: 17.4723 - val_accuracy: 0.8734 - val_loss: 18.2302\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.8866 - loss: 17.4289 - val_accuracy: 0.8734 - val_loss: 18.1060\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.8938 - loss: 17.4329 - val_accuracy: 0.8734 - val_loss: 17.9927\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.8751 - loss: 17.4373 - val_accuracy: 0.8734 - val_loss: 17.9288\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8868 - loss: 17.3990 - val_accuracy: 0.8734 - val_loss: 17.9001\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.8762 - loss: 17.4635 - val_accuracy: 0.8734 - val_loss: 17.8853\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8707 - loss: 17.4809 - val_accuracy: 0.8734 - val_loss: 17.8756\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8871 - loss: 17.4283 - val_accuracy: 0.8734 - val_loss: 17.8679\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8764 - loss: 17.4165 - val_accuracy: 0.8734 - val_loss: 17.8634\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8778 - loss: 17.4035 - val_accuracy: 0.8734 - val_loss: 17.8642\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8836 - loss: 17.3732 - val_accuracy: 0.8734 - val_loss: 17.8615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▅▇▇▇▇▇▇██▇█▇▇██▇▇█▇████▇████▇▇▇██▇█▇███</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>█████████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>▆▇█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▇▇█████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>████▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.88153</td></tr><tr><td>batch/batch_step</td><td>195</td></tr><tr><td>batch/learning_rate</td><td>0.00065</td></tr><tr><td>batch/loss</td><td>17.64853</td></tr><tr><td>epoch/accuracy</td><td>0.88146</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.00065</td></tr><tr><td>epoch/loss</td><td>16.62563</td></tr><tr><td>epoch/val_accuracy</td><td>0.87344</td></tr><tr><td>epoch/val_loss</td><td>17.86148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">first-sweep</strong> at: <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/yfydrg8r' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/yfydrg8r</a><br/> View project at: <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a><br/>Synced 5 W&B file(s), 0 media file(s), 38 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241126_151034-yfydrg8r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: erus557b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 0.055696311338659446\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/private/mlops-handson/notebooks/wandb/run-20241126_151141-erus557b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/erus557b' target=\"_blank\">first-sweep</a></strong> to <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/sweeps/59n7uolz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/erus557b' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/erus557b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train point clouds: 210\n",
      "Num train point cloud labels: 210\n",
      "Num val point clouds: 65\n",
      "Num val point cloud labels: 65\n",
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - accuracy: 0.8448 - loss: 4142.1177 - val_accuracy: 0.8734 - val_loss: 2824019.5000\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8731 - loss: 838.8868 - val_accuracy: 0.8734 - val_loss: 480720715776.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8757 - loss: 471.7996 - val_accuracy: 0.8734 - val_loss: 43942594740224.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8847 - loss: 250.2328 - val_accuracy: 0.1266 - val_loss: 47312365682688.0000\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8888 - loss: 145.2924 - val_accuracy: 0.1266 - val_loss: 2824353611776.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8772 - loss: 116.2681 - val_accuracy: 0.1266 - val_loss: 143078244352.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8812 - loss: 91.3676 - val_accuracy: 0.1266 - val_loss: 8668275712.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8802 - loss: 78.0216 - val_accuracy: 0.1266 - val_loss: 422444672.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8750 - loss: 65.7506 - val_accuracy: 0.1266 - val_loss: 16749282.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8809 - loss: 59.5682 - val_accuracy: 0.1266 - val_loss: 337247.5312\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.8812 - loss: 57.0436 - val_accuracy: 0.1391 - val_loss: 17439.5801\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8785 - loss: 52.7885 - val_accuracy: 0.2486 - val_loss: 1125.5112\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8923 - loss: 51.0148 - val_accuracy: 0.7334 - val_loss: 98.3470\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.8745 - loss: 48.6095 - val_accuracy: 0.8462 - val_loss: 60.6429\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 497ms/step - accuracy: 0.8775 - loss: 48.8205 - val_accuracy: 0.8367 - val_loss: 58.3739\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.8734 - loss: 46.4994 - val_accuracy: 0.8796 - val_loss: 54.4828\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.8788 - loss: 45.0293 - val_accuracy: 0.8803 - val_loss: 43.8594\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8784 - loss: 44.5841 - val_accuracy: 0.8791 - val_loss: 39.2474\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8750 - loss: 44.2832 - val_accuracy: 0.8802 - val_loss: 47.2530\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8818 - loss: 43.4377 - val_accuracy: 0.8815 - val_loss: 57.1972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▅▅▆▇▆▇▆█▆▅▆▆▆▆▆▅▆▆▆▆▆▆▆█▆▆▆▅▆▅▆▆▆▅▆▅▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>█████████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>▁█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▇▇▇▇▇▇▇▆█▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>████▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>███▁▁▁▁▁▁▁▁▂▇███████</td></tr><tr><td>epoch/val_loss</td><td>▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.87909</td></tr><tr><td>batch/batch_step</td><td>195</td></tr><tr><td>batch/learning_rate</td><td>0.00348</td></tr><tr><td>batch/loss</td><td>44.49416</td></tr><tr><td>epoch/accuracy</td><td>0.88017</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.00348</td></tr><tr><td>epoch/loss</td><td>41.92218</td></tr><tr><td>epoch/val_accuracy</td><td>0.88154</td></tr><tr><td>epoch/val_loss</td><td>57.1972</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">first-sweep</strong> at: <a href='https://wandb.ai/lclissa/mlops-ai_infn/runs/erus557b' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn/runs/erus557b</a><br/> View project at: <a href='https://wandb.ai/lclissa/mlops-ai_infn' target=\"_blank\">https://wandb.ai/lclissa/mlops-ai_infn</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241126_151141-erus557b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2: Define the search space\n",
    "sweep_configuration = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"val_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"init_lr\": {\"max\": 0.1, \"min\": 0.01},\n",
    "        \"batch_size\": {\"values\": [16, 32]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# 3: Start the sweep\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"mlops-ai_infn\", entity=\"lclissa\")\n",
    "\n",
    "wandb.agent(sweep_id, function=train_wrapper, count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb26f2-d401-4071-b479-d74bb8e97119",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "For more info check [wandb.sweeps](https://docs.wandb.ai/guides/sweeps/)\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
